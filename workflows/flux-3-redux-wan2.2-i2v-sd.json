{
  "90": {
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "91": {
    "inputs": {
      "text": "Ëâ≤Ë∞ÉËâ≥‰∏ΩÔºåËøáÊõùÔºåÈùôÊÄÅÔºåÁªÜËäÇÊ®°Á≥ä‰∏çÊ∏ÖÔºåÂ≠óÂπïÔºåÈ£éÊ†ºÔºå‰ΩúÂìÅÔºåÁîª‰ΩúÔºåÁîªÈù¢ÔºåÈùôÊ≠¢ÔºåÊï¥‰ΩìÂèëÁÅ∞ÔºåÊúÄÂ∑ÆË¥®ÈáèÔºå‰ΩéË¥®ÈáèÔºåJPEGÂéãÁº©ÊÆãÁïôÔºå‰∏ëÈôãÁöÑÔºåÊÆãÁº∫ÁöÑÔºåÂ§ö‰ΩôÁöÑÊâãÊåáÔºåÁîªÂæó‰∏çÂ•ΩÁöÑÊâãÈÉ®ÔºåÁîªÂæó‰∏çÂ•ΩÁöÑËÑ∏ÈÉ®ÔºåÁï∏ÂΩ¢ÁöÑÔºåÊØÅÂÆπÁöÑÔºåÂΩ¢ÊÄÅÁï∏ÂΩ¢ÁöÑËÇ¢‰ΩìÔºåÊâãÊåáËûçÂêàÔºåÈùôÊ≠¢‰∏çÂä®ÁöÑÁîªÈù¢ÔºåÊùÇ‰π±ÁöÑËÉåÊôØÔºå‰∏âÊù°ËÖøÔºåËÉåÊôØ‰∫∫ÂæàÂ§öÔºåÂÄíÁùÄËµ∞",
      "clip": [
        "90",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "92": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "93": {
    "inputs": {
      "shift": 4,
      "model": [
        "111",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "95": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": [
        "174",
        0
      ],
      "steps": [
        "172",
        0
      ],
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": [
        "173",
        0
      ],
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "140",
        0
      ],
      "positive": [
        "176",
        0
      ],
      "negative": [
        "176",
        1
      ],
      "latent_image": [
        "96",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "96": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": [
        "174",
        0
      ],
      "steps": [
        "172",
        0
      ],
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": 0,
      "end_at_step": [
        "173",
        0
      ],
      "return_with_leftover_noise": "enable",
      "model": [
        "93",
        0
      ],
      "positive": [
        "176",
        0
      ],
      "negative": [
        "176",
        1
      ],
      "latent_image": [
        "176",
        2
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "97": {
    "inputs": {
      "samples": [
        "95",
        0
      ],
      "vae": [
        "92",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "99": {
    "inputs": {
      "text": [
        "230",
        0
      ],
      "clip": [
        "90",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "101": {
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "102": {
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "110": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "101",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "111": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "110",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "112": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "102",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "113": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "112",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "115": {
    "inputs": {
      "mmaudio_model": "mmaudio_large_44k_v2_fp32.safetensors",
      "base_precision": "fp32"
    },
    "class_type": "MMAudioModelLoader",
    "_meta": {
      "title": "MMAudio ModelLoader"
    }
  },
  "116": {
    "inputs": {
      "vae_model": "mmaudio_vae_44k_fp32.safetensors",
      "synchformer_model": "mmaudio_synchformer_fp32.safetensors",
      "clip_model": "apple_DFN5B-CLIP-ViT-H-14-384_fp32.safetensors",
      "mode": "44k",
      "precision": "fp32"
    },
    "class_type": "MMAudioFeatureUtilsLoader",
    "_meta": {
      "title": "MMAudio FeatureUtilsLoader"
    }
  },
  "117": {
    "inputs": {
      "duration": [
        "165",
        0
      ],
      "steps": 50,
      "cfg": 4.5,
      "seed": 855394697552323,
      "prompt": [
        "234",
        0
      ],
      "negative_prompt": "",
      "mask_away_clip": false,
      "force_offload": false,
      "mmaudio_model": [
        "115",
        0
      ],
      "feature_utils": [
        "116",
        0
      ],
      "images": [
        "121",
        0
      ]
    },
    "class_type": "MMAudioSampler",
    "_meta": {
      "title": "MMAudio Sampler"
    }
  },
  "121": {
    "inputs": {
      "ckpt_name": "rife49.pth",
      "clear_cache_after_n_frames": 10,
      "multiplier": 2,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "frames": [
        "97",
        0
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "125": {
    "inputs": {
      "frame_rate": 32,
      "loop_count": 0,
      "filename_prefix": "wan_video_T2V",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "121",
        0
      ],
      "audio": [
        "117",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "SAVE_VIDEO"
    }
  },
  "140": {
    "inputs": {
      "shift": 4,
      "model": [
        "171",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "143": {
    "inputs": {
      "value": 1280
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@WIDTH"
    }
  },
  "144": {
    "inputs": {
      "value": 720
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@HEIGHT"
    }
  },
  "145": {
    "inputs": {
      "value": 180
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@FRAME_LENGTH"
    }
  },
  "161": {
    "inputs": {
      "op": "Sub",
      "a": [
        "163",
        0
      ],
      "b": 1
    },
    "class_type": "CM_FloatBinaryOperation",
    "_meta": {
      "title": "FloatBinaryOperation"
    }
  },
  "163": {
    "inputs": {
      "a": [
        "145",
        0
      ]
    },
    "class_type": "CM_IntToFloat",
    "_meta": {
      "title": "IntToFloat"
    }
  },
  "165": {
    "inputs": {
      "op": "Div",
      "a": [
        "161",
        0
      ],
      "b": 16
    },
    "class_type": "CM_FloatBinaryOperation",
    "_meta": {
      "title": "FloatBinaryOperation"
    }
  },
  "171": {
    "inputs": {
      "lora_name": "lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
      "strength_model": 0.5,
      "model": [
        "113",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "172": {
    "inputs": {
      "value": 8
    },
    "class_type": "Int",
    "_meta": {
      "title": "Steps"
    }
  },
  "173": {
    "inputs": {
      "expression": "a / 2",
      "a": [
        "172",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression üêç"
    }
  },
  "174": {
    "inputs": {
      "seed": 1079955028680999
    },
    "class_type": "Seed Everywhere",
    "_meta": {
      "title": "Seed Everywhere"
    }
  },
  "176": {
    "inputs": {
      "width": [
        "143",
        0
      ],
      "height": [
        "144",
        0
      ],
      "length": 81,
      "batch_size": 1,
      "positive": [
        "99",
        0
      ],
      "negative": [
        "91",
        0
      ],
      "vae": [
        "92",
        0
      ],
      "start_image": [
        "212",
        0
      ]
    },
    "class_type": "WanImageToVideo",
    "_meta": {
      "title": "WanImageToVideo"
    }
  },
  "200": {
    "inputs": {
      "width": 1280,
      "height": 720,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "201": {
    "inputs": {
      "max_shift": 1.15,
      "base_shift": 0.5,
      "width": 1280,
      "height": 720,
      "model": [
        "207",
        0
      ]
    },
    "class_type": "ModelSamplingFlux",
    "_meta": {
      "title": "ModelSamplingFlux"
    }
  },
  "202": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "203": {
    "inputs": {
      "scheduler": "simple",
      "steps": 20,
      "denoise": 1,
      "model": [
        "201",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "204": {
    "inputs": {
      "noise_seed": 643467875793462
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "205": {
    "inputs": {
      "strength": 1,
      "strength_type": "multiply",
      "conditioning": [
        "206",
        0
      ],
      "style_model": [
        "210",
        0
      ],
      "clip_vision_output": [
        "218",
        0
      ]
    },
    "class_type": "StyleModelApply",
    "_meta": {
      "title": "Apply Style Model"
    }
  },
  "206": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "227",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "207": {
    "inputs": {
      "unet_name": "flux1-dev.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "208": {
    "inputs": {
      "clip_name1": "t5xxl_fp16.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "209": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "210": {
    "inputs": {
      "style_model_name": "flux1-redux-dev.safetensors"
    },
    "class_type": "StyleModelLoader",
    "_meta": {
      "title": "Load Style Model"
    }
  },
  "211": {
    "inputs": {
      "noise": [
        "204",
        0
      ],
      "guider": [
        "214",
        0
      ],
      "sampler": [
        "202",
        0
      ],
      "sigmas": [
        "203",
        0
      ],
      "latent_image": [
        "200",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "212": {
    "inputs": {
      "samples": [
        "211",
        0
      ],
      "vae": [
        "209",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "214": {
    "inputs": {
      "model": [
        "201",
        0
      ],
      "conditioning": [
        "228",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "215": {
    "inputs": {
      "image": "Clipboard - 2024-08-16 21.21.38.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "@IMAGE_2"
    }
  },
  "217": {
    "inputs": {
      "strength": 1,
      "strength_type": "multiply",
      "conditioning": [
        "205",
        0
      ],
      "style_model": [
        "210",
        0
      ],
      "clip_vision_output": [
        "223",
        0
      ]
    },
    "class_type": "StyleModelApply",
    "_meta": {
      "title": "Apply Style Model"
    }
  },
  "218": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "219",
        0
      ],
      "image": [
        "243",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "219": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "223": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "219",
        0
      ],
      "image": [
        "248",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "224": {
    "inputs": {
      "image": "@ihatecigs (2).jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "@IMAGE_3"
    }
  },
  "225": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "219",
        0
      ],
      "image": [
        "249",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "226": {
    "inputs": {
      "image": "Parker Ito and Dean Kissick - by Tom - Art of Conversation (3).jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "@IMAGE_1"
    }
  },
  "227": {
    "inputs": {
      "text": "",
      "clip": [
        "208",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "228": {
    "inputs": {
      "strength": 1,
      "strength_type": "multiply",
      "conditioning": [
        "217",
        0
      ],
      "style_model": [
        "210",
        0
      ],
      "clip_vision_output": [
        "225",
        0
      ]
    },
    "class_type": "StyleModelApply",
    "_meta": {
      "title": "Apply Style Model"
    }
  },
  "229": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "212",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "230": {
    "inputs": {
      "text": "Image a scene for this image. Do not describe image, but rather. Imagine how this image would change as a video. Describe for text and image to video for Wan 2.2. Print only prompt. Prefer JSON output. \n",
      "model": "Qwen2.5-VL-3B-Instruct",
      "quantization": "none",
      "keep_model_loaded": false,
      "temperature": 0.7,
      "max_new_tokens": 512,
      "seed": 1004,
      "video_path": "",
      "image": [
        "212",
        0
      ]
    },
    "class_type": "Qwen2.5VL",
    "_meta": {
      "title": "Qwen2.5VL GENERATES MOTION PROMPT"
    }
  },
  "234": {
    "inputs": {
      "text": "Imagine the soundscape for this image. Do not describe the image visually, but rather imagine what sounds would emanate from this scene. Describe the audio environment, ambient noises, and sound effects. Print only the audio prompt for MMAUDIO generation.",
      "model": "Qwen2.5-VL-3B-Instruct",
      "quantization": "none",
      "keep_model_loaded": false,
      "temperature": 0.7,
      "max_new_tokens": 512,
      "seed": 488,
      "video_path": "",
      "image": [
        "212",
        0
      ]
    },
    "class_type": "Qwen2.5VL",
    "_meta": {
      "title": "Qwen2.5VL GENERATES AUDIO PROMPT"
    }
  },
  "236": {
    "inputs": {
      "text_0": "```json\n{\n  \"prompt\": \"As the video progresses, the tree begins to come to life, its branches swaying gently in the breeze. The eyes of the tree open wider, revealing a deep red glow that illuminates the surrounding landscape. The trunk starts to move, as if breathing, and the roots spread out, reaching towards the ground. The background transitions from a serene sunset to a mystical, otherworldly atmosphere with swirling clouds and glowing lights. The stone monument and bamboo sticks remain static throughout, serving as silent witnesses to the transformation.\"\n}\n```",
      "text": [
        "230",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text üêç"
    }
  },
  "237": {
    "inputs": {
      "text_0": "The audio environment in this scene is serene yet eerie. The background features a soft, gentle breeze rustling through the tree's leaves, creating a soothing sound. The distant mountains and sky evoke a sense of calm, with occasional whispers of wind carrying distant sounds. The stone structure and bamboo poles add to the ambiance with subtle, rhythmic movements. The overall atmosphere is one of quiet contemplation, with occasional distant animal calls or bird songs breaking the silence.",
      "text": [
        "234",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text üêç"
    }
  },
  "241": {
    "inputs": {
      "image": "ComfyUI_00098_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "243": {
    "inputs": {
      "url_or_path": ""
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_1"
    }
  },
  "248": {
    "inputs": {
      "url_or_path": ""
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_2"
    }
  },
  "249": {
    "inputs": {
      "url_or_path": ""
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_3"
    }
  }
}