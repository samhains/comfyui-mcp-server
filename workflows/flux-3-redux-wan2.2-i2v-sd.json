{
  "90": {
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "91": {
    "inputs": {
      "text": "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走",
      "clip": [
        "90",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "92": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "93": {
    "inputs": {
      "shift": 4,
      "model": [
        "111",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "95": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": [
        "174",
        0
      ],
      "steps": [
        "172",
        0
      ],
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": [
        "173",
        0
      ],
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "140",
        0
      ],
      "positive": [
        "176",
        0
      ],
      "negative": [
        "176",
        1
      ],
      "latent_image": [
        "96",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "96": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": [
        "174",
        0
      ],
      "steps": [
        "172",
        0
      ],
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": 0,
      "end_at_step": [
        "173",
        0
      ],
      "return_with_leftover_noise": "enable",
      "model": [
        "93",
        0
      ],
      "positive": [
        "176",
        0
      ],
      "negative": [
        "176",
        1
      ],
      "latent_image": [
        "176",
        2
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "97": {
    "inputs": {
      "samples": [
        "95",
        0
      ],
      "vae": [
        "92",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "99": {
    "inputs": {
      "text": [
        "230",
        0
      ],
      "clip": [
        "90",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "101": {
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "102": {
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "110": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "101",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "111": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "110",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "112": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "102",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "113": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "112",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "115": {
    "inputs": {
      "mmaudio_model": "mmaudio_large_44k_v2_fp32.safetensors",
      "base_precision": "fp32"
    },
    "class_type": "MMAudioModelLoader",
    "_meta": {
      "title": "MMAudio ModelLoader"
    }
  },
  "116": {
    "inputs": {
      "vae_model": "mmaudio_vae_44k_fp32.safetensors",
      "synchformer_model": "mmaudio_synchformer_fp32.safetensors",
      "clip_model": "apple_DFN5B-CLIP-ViT-H-14-384_fp32.safetensors",
      "mode": "44k",
      "precision": "fp32"
    },
    "class_type": "MMAudioFeatureUtilsLoader",
    "_meta": {
      "title": "MMAudio FeatureUtilsLoader"
    }
  },
  "117": {
    "inputs": {
      "duration": [
        "165",
        0
      ],
      "steps": 50,
      "cfg": 4.5,
      "seed": 855394697552323,
      "prompt": [
        "234",
        0
      ],
      "negative_prompt": "",
      "mask_away_clip": false,
      "force_offload": false,
      "mmaudio_model": [
        "115",
        0
      ],
      "feature_utils": [
        "116",
        0
      ],
      "images": [
        "121",
        0
      ]
    },
    "class_type": "MMAudioSampler",
    "_meta": {
      "title": "MMAudio Sampler"
    }
  },
  "121": {
    "inputs": {
      "ckpt_name": "rife49.pth",
      "clear_cache_after_n_frames": 10,
      "multiplier": 2,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "frames": [
        "97",
        0
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "125": {
    "inputs": {
      "frame_rate": 32,
      "loop_count": 0,
      "filename_prefix": "wan_video_T2V",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "121",
        0
      ],
      "audio": [
        "117",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "SAVE_VIDEO"
    }
  },
  "140": {
    "inputs": {
      "shift": 4,
      "model": [
        "171",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "143": {
    "inputs": {
      "value": 1280
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@WIDTH"
    }
  },
  "144": {
    "inputs": {
      "value": 720
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@HEIGHT"
    }
  },
  "145": {
    "inputs": {
      "value": 180
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@FRAME_LENGTH"
    }
  },
  "161": {
    "inputs": {
      "op": "Sub",
      "a": [
        "163",
        0
      ],
      "b": 1
    },
    "class_type": "CM_FloatBinaryOperation",
    "_meta": {
      "title": "FloatBinaryOperation"
    }
  },
  "163": {
    "inputs": {
      "a": [
        "145",
        0
      ]
    },
    "class_type": "CM_IntToFloat",
    "_meta": {
      "title": "IntToFloat"
    }
  },
  "165": {
    "inputs": {
      "op": "Div",
      "a": [
        "161",
        0
      ],
      "b": 16
    },
    "class_type": "CM_FloatBinaryOperation",
    "_meta": {
      "title": "FloatBinaryOperation"
    }
  },
  "171": {
    "inputs": {
      "lora_name": "lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
      "strength_model": 0.5,
      "model": [
        "113",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "172": {
    "inputs": {
      "value": 8
    },
    "class_type": "Int",
    "_meta": {
      "title": "Steps"
    }
  },
  "173": {
    "inputs": {
      "expression": "a / 2",
      "a": [
        "172",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression 🐍"
    }
  },
  "174": {
    "inputs": {
      "seed": 1079955028680999
    },
    "class_type": "Seed Everywhere",
    "_meta": {
      "title": "Seed Everywhere"
    }
  },
  "176": {
    "inputs": {
      "width": [
        "143",
        0
      ],
      "height": [
        "144",
        0
      ],
      "length": 81,
      "batch_size": 1,
      "positive": [
        "99",
        0
      ],
      "negative": [
        "91",
        0
      ],
      "vae": [
        "92",
        0
      ],
      "start_image": [
        "212",
        0
      ]
    },
    "class_type": "WanImageToVideo",
    "_meta": {
      "title": "WanImageToVideo"
    }
  },
  "200": {
    "inputs": {
      "width": 1280,
      "height": 720,
      "batch_size": 1
    },
    "class_type": "EmptySD3LatentImage",
    "_meta": {
      "title": "EmptySD3LatentImage"
    }
  },
  "201": {
    "inputs": {
      "max_shift": 1.15,
      "base_shift": 0.5,
      "width": 1280,
      "height": 720,
      "model": [
        "207",
        0
      ]
    },
    "class_type": "ModelSamplingFlux",
    "_meta": {
      "title": "ModelSamplingFlux"
    }
  },
  "202": {
    "inputs": {
      "sampler_name": "euler"
    },
    "class_type": "KSamplerSelect",
    "_meta": {
      "title": "KSamplerSelect"
    }
  },
  "203": {
    "inputs": {
      "scheduler": "simple",
      "steps": 20,
      "denoise": 1,
      "model": [
        "201",
        0
      ]
    },
    "class_type": "BasicScheduler",
    "_meta": {
      "title": "BasicScheduler"
    }
  },
  "204": {
    "inputs": {
      "noise_seed": 643467875793462
    },
    "class_type": "RandomNoise",
    "_meta": {
      "title": "RandomNoise"
    }
  },
  "205": {
    "inputs": {
      "strength": 1,
      "strength_type": "multiply",
      "conditioning": [
        "206",
        0
      ],
      "style_model": [
        "210",
        0
      ],
      "clip_vision_output": [
        "218",
        0
      ]
    },
    "class_type": "StyleModelApply",
    "_meta": {
      "title": "Apply Style Model"
    }
  },
  "206": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "227",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "207": {
    "inputs": {
      "unet_name": "flux1-dev.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "208": {
    "inputs": {
      "clip_name1": "t5xxl_fp16.safetensors",
      "clip_name2": "clip_l.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "209": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "210": {
    "inputs": {
      "style_model_name": "flux1-redux-dev.safetensors"
    },
    "class_type": "StyleModelLoader",
    "_meta": {
      "title": "Load Style Model"
    }
  },
  "211": {
    "inputs": {
      "noise": [
        "204",
        0
      ],
      "guider": [
        "214",
        0
      ],
      "sampler": [
        "202",
        0
      ],
      "sigmas": [
        "203",
        0
      ],
      "latent_image": [
        "200",
        0
      ]
    },
    "class_type": "SamplerCustomAdvanced",
    "_meta": {
      "title": "SamplerCustomAdvanced"
    }
  },
  "212": {
    "inputs": {
      "samples": [
        "211",
        0
      ],
      "vae": [
        "209",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "214": {
    "inputs": {
      "model": [
        "201",
        0
      ],
      "conditioning": [
        "228",
        0
      ]
    },
    "class_type": "BasicGuider",
    "_meta": {
      "title": "BasicGuider"
    }
  },
  "215": {
    "inputs": {
      "image": "Clipboard - 2024-08-16 21.21.38.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "@IMAGE_2"
    }
  },
  "217": {
    "inputs": {
      "strength": 1,
      "strength_type": "multiply",
      "conditioning": [
        "205",
        0
      ],
      "style_model": [
        "210",
        0
      ],
      "clip_vision_output": [
        "223",
        0
      ]
    },
    "class_type": "StyleModelApply",
    "_meta": {
      "title": "Apply Style Model"
    }
  },
  "218": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "219",
        0
      ],
      "image": [
        "243",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "219": {
    "inputs": {
      "clip_name": "sigclip_vision_patch14_384.safetensors"
    },
    "class_type": "CLIPVisionLoader",
    "_meta": {
      "title": "Load CLIP Vision"
    }
  },
  "223": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "219",
        0
      ],
      "image": [
        "248",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "224": {
    "inputs": {
      "image": "@ihatecigs (2).jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "@IMAGE_3"
    }
  },
  "225": {
    "inputs": {
      "crop": "center",
      "clip_vision": [
        "219",
        0
      ],
      "image": [
        "249",
        0
      ]
    },
    "class_type": "CLIPVisionEncode",
    "_meta": {
      "title": "CLIP Vision Encode"
    }
  },
  "226": {
    "inputs": {
      "image": "Parker Ito and Dean Kissick - by Tom - Art of Conversation (3).jpg"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "@IMAGE_1"
    }
  },
  "227": {
    "inputs": {
      "text": "",
      "clip": [
        "208",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "228": {
    "inputs": {
      "strength": 1,
      "strength_type": "multiply",
      "conditioning": [
        "217",
        0
      ],
      "style_model": [
        "210",
        0
      ],
      "clip_vision_output": [
        "225",
        0
      ]
    },
    "class_type": "StyleModelApply",
    "_meta": {
      "title": "Apply Style Model"
    }
  },
  "229": {
    "inputs": {
      "filename_prefix": "ComfyUI",
      "images": [
        "212",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "230": {
    "inputs": {
      "text": "Image a scene for this image. Do not describe image, but rather. Imagine how this image would change as a video. Describe for text and image to video for Wan 2.2. Print only prompt. Prefer JSON output. \n",
      "model": "Qwen2.5-VL-3B-Instruct",
      "quantization": "none",
      "keep_model_loaded": false,
      "temperature": 0.7,
      "max_new_tokens": 512,
      "seed": 1004,
      "video_path": "",
      "image": [
        "212",
        0
      ]
    },
    "class_type": "Qwen2.5VL",
    "_meta": {
      "title": "Qwen2.5VL GENERATES MOTION PROMPT"
    }
  },
  "234": {
    "inputs": {
      "text": "Imagine the soundscape for this image. Do not describe the image visually, but rather imagine what sounds would emanate from this scene. Describe the audio environment, ambient noises, and sound effects. Print only the audio prompt for MMAUDIO generation.",
      "model": "Qwen2.5-VL-3B-Instruct",
      "quantization": "none",
      "keep_model_loaded": false,
      "temperature": 0.7,
      "max_new_tokens": 512,
      "seed": 488,
      "video_path": "",
      "image": [
        "212",
        0
      ]
    },
    "class_type": "Qwen2.5VL",
    "_meta": {
      "title": "Qwen2.5VL GENERATES AUDIO PROMPT"
    }
  },
  "236": {
    "inputs": {
      "text_0": "```json\n{\n  \"prompt\": \"As the video progresses, the tree begins to come to life, its branches swaying gently in the breeze. The eyes of the tree open wider, revealing a deep red glow that illuminates the surrounding landscape. The trunk starts to move, as if breathing, and the roots spread out, reaching towards the ground. The background transitions from a serene sunset to a mystical, otherworldly atmosphere with swirling clouds and glowing lights. The stone monument and bamboo sticks remain static throughout, serving as silent witnesses to the transformation.\"\n}\n```",
      "text": [
        "230",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text 🐍"
    }
  },
  "237": {
    "inputs": {
      "text_0": "The audio environment in this scene is serene yet eerie. The background features a soft, gentle breeze rustling through the tree's leaves, creating a soothing sound. The distant mountains and sky evoke a sense of calm, with occasional whispers of wind carrying distant sounds. The stone structure and bamboo poles add to the ambiance with subtle, rhythmic movements. The overall atmosphere is one of quiet contemplation, with occasional distant animal calls or bird songs breaking the silence.",
      "text": [
        "234",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text 🐍"
    }
  },
  "241": {
    "inputs": {
      "image": "ComfyUI_00098_.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "243": {
    "inputs": {
      "url_or_path": ""
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_1"
    }
  },
  "248": {
    "inputs": {
      "url_or_path": ""
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_2"
    }
  },
  "249": {
    "inputs": {
      "url_or_path": ""
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_3"
    }
  }
}