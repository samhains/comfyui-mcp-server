{
  "90": {
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "91": {
    "inputs": {
      "text": "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走",
      "clip": [
        "90",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "92": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "93": {
    "inputs": {
      "shift": 4,
      "model": [
        "111",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "95": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": [
        "174",
        0
      ],
      "steps": [
        "172",
        0
      ],
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": [
        "173",
        0
      ],
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "140",
        0
      ],
      "positive": [
        "200",
        0
      ],
      "negative": [
        "200",
        1
      ],
      "latent_image": [
        "96",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "96": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": [
        "174",
        0
      ],
      "steps": [
        "172",
        0
      ],
      "cfg": 3.5,
      "sampler_name": "euler",
      "scheduler": "beta",
      "start_at_step": 0,
      "end_at_step": [
        "173",
        0
      ],
      "return_with_leftover_noise": "enable",
      "model": [
        "93",
        0
      ],
      "positive": [
        "200",
        0
      ],
      "negative": [
        "200",
        1
      ],
      "latent_image": [
        "200",
        2
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "97": {
    "inputs": {
      "samples": [
        "95",
        0
      ],
      "vae": [
        "92",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "99": {
    "inputs": {
      "text": [
        "141",
        0
      ],
      "clip": [
        "90",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "101": {
    "inputs": {
      "unet_name": "wan2.2_i2v_high_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "102": {
    "inputs": {
      "unet_name": "wan2.2_i2v_low_noise_14B_fp8_scaled.safetensors",
      "weight_dtype": "fp8_e4m3fn_fast"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "110": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "101",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "111": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "110",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "112": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "102",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "113": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "112",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "115": {
    "inputs": {
      "mmaudio_model": "mmaudio_large_44k_v2_fp32.safetensors",
      "base_precision": "fp32"
    },
    "class_type": "MMAudioModelLoader",
    "_meta": {
      "title": "MMAudio ModelLoader"
    }
  },
  "116": {
    "inputs": {
      "vae_model": "mmaudio_vae_44k_fp32.safetensors",
      "synchformer_model": "mmaudio_synchformer_fp32.safetensors",
      "clip_model": "apple_DFN5B-CLIP-ViT-H-14-384_fp32.safetensors",
      "mode": "44k",
      "precision": "fp32"
    },
    "class_type": "MMAudioFeatureUtilsLoader",
    "_meta": {
      "title": "MMAudio FeatureUtilsLoader"
    }
  },
  "117": {
    "inputs": {
      "duration": [
        "165",
        0
      ],
      "steps": 50,
      "cfg": 4.5,
      "seed": 337623049650465,
      "prompt": [
        "271",
        0
      ],
      "negative_prompt": "",
      "mask_away_clip": false,
      "force_offload": false,
      "mmaudio_model": [
        "115",
        0
      ],
      "feature_utils": [
        "116",
        0
      ],
      "images": [
        "121",
        0
      ]
    },
    "class_type": "MMAudioSampler",
    "_meta": {
      "title": "MMAudio Sampler"
    }
  },
  "121": {
    "inputs": {
      "ckpt_name": "rife49.pth",
      "clear_cache_after_n_frames": 10,
      "multiplier": 2,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "frames": [
        "97",
        0
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "125": {
    "inputs": {
      "frame_rate": 32,
      "loop_count": 0,
      "filename_prefix": "wan_video_T2V",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "121",
        0
      ],
      "audio": [
        "117",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "SAVE_VIDEO"
    }
  },
  "140": {
    "inputs": {
      "shift": 4,
      "model": [
        "171",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "141": {
    "inputs": {
      "value": ""
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "@PROMPT"
    }
  },
  "143": {
    "inputs": {
      "value": 640
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@WIDTH"
    }
  },
  "144": {
    "inputs": {
      "value": 640
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@HEIGHT"
    }
  },
  "145": {
    "inputs": {
      "value": 81
    },
    "class_type": "PrimitiveInt",
    "_meta": {
      "title": "@FRAME_LENGTH"
    }
  },
  "147": {
    "inputs": {
      "value": ""
    },
    "class_type": "PrimitiveStringMultiline",
    "_meta": {
      "title": "@AUDIO_PROMPT"
    }
  },
  "161": {
    "inputs": {
      "op": "Sub",
      "a": [
        "163",
        0
      ],
      "b": 1
    },
    "class_type": "CM_FloatBinaryOperation",
    "_meta": {
      "title": "FloatBinaryOperation"
    }
  },
  "163": {
    "inputs": {
      "a": [
        "145",
        0
      ]
    },
    "class_type": "CM_IntToFloat",
    "_meta": {
      "title": "IntToFloat"
    }
  },
  "165": {
    "inputs": {
      "op": "Div",
      "a": [
        "161",
        0
      ],
      "b": 16
    },
    "class_type": "CM_FloatBinaryOperation",
    "_meta": {
      "title": "FloatBinaryOperation"
    }
  },
  "171": {
    "inputs": {
      "lora_name": "lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
      "strength_model": 0.5,
      "model": [
        "113",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "172": {
    "inputs": {
      "value": 8
    },
    "class_type": "Int",
    "_meta": {
      "title": "Steps"
    }
  },
  "173": {
    "inputs": {
      "expression": "a / 2",
      "a": [
        "172",
        0
      ]
    },
    "class_type": "MathExpression|pysssss",
    "_meta": {
      "title": "Math Expression 🐍"
    }
  },
  "174": {
    "inputs": {
      "seed": 1112781977207506
    },
    "class_type": "Seed Everywhere",
    "_meta": {
      "title": "Seed Everywhere"
    }
  },
  "200": {
    "inputs": {
      "width": [
        "143",
        0
      ],
      "height": [
        "144",
        0
      ],
      "length": [
        "145",
        0
      ],
      "batch_size": 1,
      "positive": [
        "99",
        0
      ],
      "negative": [
        "91",
        0
      ],
      "vae": [
        "92",
        0
      ],
      "start_image": [
        "278",
        0
      ],
      "end_image": [
        "280",
        0
      ]
    },
    "class_type": "WanFirstLastFrameToVideo",
    "_meta": {
      "title": "WanFirstLastFrameToVideo"
    }
  },
  "269": {
    "inputs": {},
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text 🐍"
    }
  },
  "270": {
    "inputs": {
      "text": "Imagine the soundscape for these images. Do not describe the images visually, but rather imagine what sounds would emanate from this scene. Describe the audio environment, ambient noises, and sound effects. Print only the audio prompt for MMAUDIO generation. ",
      "model": "Qwen2.5-VL-3B-Instruct",
      "quantization": "none",
      "keep_model_loaded": false,
      "temperature": 0.7,
      "max_new_tokens": 512,
      "seed": 1016,
      "video_path": "",
      "image": [
        "276",
        0
      ]
    },
    "class_type": "Qwen2.5VL",
    "_meta": {
      "title": "Qwen2.5VL GENERATES AUDIO PROMPT"
    }
  },
  "271": {
    "inputs": {
      "text": [
        "270",
        0
      ]
    },
    "class_type": "ShowText|pysssss",
    "_meta": {
      "title": "Show Text 🐍"
    }
  },
  "276": {
    "inputs": {
      "direction": "right",
      "match_image_size": true,
      "image1": [
        "278",
        0
      ],
      "image2": [
        "280",
        0
      ]
    },
    "class_type": "ImageConcanate",
    "_meta": {
      "title": "Image Concatenate"
    }
  },
  "278": {
    "inputs": {
      "url_or_path": "https://idyoveanwiuwcvgxijtz.supabase.co/storage/v1/object/public/eagle-images/images/LO25GZC6QIFHY.jpg"
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_START"
    }
  },
  "279": {
    "inputs": {
      "images": [
        "278",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  },
  "280": {
    "inputs": {
      "url_or_path": "https://idyoveanwiuwcvgxijtz.supabase.co/storage/v1/object/public/eagle-images/images/LYYN40876GBHO.png"
    },
    "class_type": "LoadImageFromUrlOrPath",
    "_meta": {
      "title": "@IMAGE_END"
    }
  },
  "282": {
    "inputs": {
      "images": [
        "280",
        0
      ]
    },
    "class_type": "PreviewImage",
    "_meta": {
      "title": "Preview Image"
    }
  }
}