{
  "6": {
    "inputs": {
      "text": "",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Positive Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走",
      "clip": [
        "38",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Negative Prompt)"
    }
  },
  "8": {
    "inputs": {
      "samples": [
        "58",
        0
      ],
      "vae": [
        "39",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "37": {
    "inputs": {
      "unet_name": "Wan2_2-T2V-A14B-LOW_fp8_e4m3fn_scaled_KJ.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "38": {
    "inputs": {
      "clip_name": "umt5_xxl_fp8_e4m3fn_scaled.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "39": {
    "inputs": {
      "vae_name": "wan_2.1_vae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "56": {
    "inputs": {
      "unet_name": "Wan2_2-T2V-A14B_HIGH_fp8_e4m3fn_scaled_KJ.safetensors",
      "weight_dtype": "default"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "57": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": 645796516159588,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "start_at_step": 0,
      "end_at_step": 3,
      "return_with_leftover_noise": "enable",
      "model": [
        "84:54",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "59",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "58": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": 0,
      "steps": 8,
      "cfg": 1,
      "sampler_name": "euler",
      "scheduler": "simple",
      "start_at_step": 3,
      "end_at_step": 10000,
      "return_with_leftover_noise": "disable",
      "model": [
        "84:55",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "57",
        0
      ]
    },
    "class_type": "KSamplerAdvanced",
    "_meta": {
      "title": "KSampler (Advanced)"
    }
  },
  "59": {
    "inputs": {
      "width": 720,
      "height": 1280,
      "length": 181,
      "batch_size": 1
    },
    "class_type": "EmptyHunyuanLatentVideo",
    "_meta": {
      "title": "EmptyHunyuanLatentVideo"
    }
  },
  "74": {
    "inputs": {
      "frame_rate": 32,
      "loop_count": 0,
      "filename_prefix": "wan_video_T2V",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "83:79",
        0
      ],
      "audio": [
        "83:75",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Saved MP4 With Audio"
    }
  },
  "84:55": {
    "inputs": {
      "shift": 8,
      "model": [
        "84:73",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "84:67": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "84:69",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "84:68": {
    "inputs": {
      "enable_fp16_accumulation": true,
      "model": [
        "84:66",
        0
      ]
    },
    "class_type": "ModelPatchTorchSettings",
    "_meta": {
      "title": "Model Patch Torch Settings"
    }
  },
  "84:69": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "56",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "84:66": {
    "inputs": {
      "sage_attention": "auto",
      "model": [
        "37",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "84:65": {
    "inputs": {
      "lora_name": "lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
      "strength_model": 3.0000000000000004,
      "model": [
        "84:68",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "84:64": {
    "inputs": {
      "lora_name": "lightx2v_I2V_14B_480p_cfg_step_distill_rank64_bf16.safetensors",
      "strength_model": 1.5000000000000002,
      "model": [
        "84:67",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "84:72": {
    "inputs": {
      "lora_name": "goldenboylora-e504.safetensors",
      "strength_model": 1.0000000000000002,
      "model": [
        "84:65",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "84:54": {
    "inputs": {
      "shift": 8.000000000000002,
      "model": [
        "84:72",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "84:73": {
    "inputs": {
      "lora_name": "goldenboylora-e504.safetensors",
      "strength_model": 1.0000000000000002,
      "model": [
        "84:64",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "83:75": {
    "inputs": {
      "duration": 11.3125,
      "steps": 50,
      "cfg": 4.5,
      "seed": 1,
      "prompt": "A police car siren",
      "negative_prompt": "",
      "mask_away_clip": false,
      "force_offload": true,
      "mmaudio_model": [
        "83:76",
        0
      ],
      "feature_utils": [
        "83:77",
        0
      ],
      "images": [
        "83:79",
        0
      ]
    },
    "class_type": "MMAudioSampler",
    "_meta": {
      "title": "MMAudio Sampler"
    }
  },
  "83:79": {
    "inputs": {
      "ckpt_name": "rife49.pth",
      "clear_cache_after_n_frames": 10,
      "multiplier": 2,
      "fast_mode": true,
      "ensemble": true,
      "scale_factor": 1,
      "frames": [
        "8",
        0
      ]
    },
    "class_type": "RIFE VFI",
    "_meta": {
      "title": "RIFE VFI (recommend rife47 and rife49)"
    }
  },
  "83:76": {
    "inputs": {
      "mmaudio_model": "mmaudio_large_44k_v2_fp32.safetensors",
      "base_precision": "fp32"
    },
    "class_type": "MMAudioModelLoader",
    "_meta": {
      "title": "MMAudio ModelLoader"
    }
  },
  "83:77": {
    "inputs": {
      "vae_model": "mmaudio_vae_44k_fp32.safetensors",
      "synchformer_model": "mmaudio_synchformer_fp32.safetensors",
      "clip_model": "apple_DFN5B-CLIP-ViT-H-14-384_fp32.safetensors",
      "mode": "44k",
      "precision": "fp32"
    },
    "class_type": "MMAudioFeatureUtilsLoader",
    "_meta": {
      "title": "MMAudio FeatureUtilsLoader"
    }
  }
}
